import logging
import asyncio
from typing import Optional

from telegram import Update
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    filters,
    ContextTypes,
)
import aiohttp
import json

# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³
from config import (
    TELEGRAM_BOT_TOKEN,
    DEEPSEEK_API_KEY,
    CHATGPT_API_KEY,
    LOG_LEVEL,
    MIN_TEXT_LENGTH,
    ANALYSIS_TIMEOUT,
)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ›ĞĞ“Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ•
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=getattr(logging, LOG_LEVEL, logging.INFO)
)
logger = logging.getLogger(__name__)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞœĞ ĞĞĞĞ›Ğ˜Ğ—Ğ (Ğ›ĞĞšĞĞ›Ğ¬ĞĞĞ¯)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class FraudAnalyzer:
    """Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ° Ğ½Ğ° Ğ¼Ğ¾ÑˆĞµĞ½Ğ½Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾"""
    
    FRAUD_PATTERNS = {
        "credit": {
            "keywords": [
                "ĞºÑ€ĞµĞ´Ğ¸Ñ‚", "Ğ¾Ğ´Ğ¾Ğ±Ñ€ĞµĞ½", "Ğ·Ğ°Ğ¹Ğ¼", "Ğ´ĞµĞ½ÑŒĞ³Ğ¸", "Ğ±Ğ°Ğ½Ğº",
                "ÑÑ‡ĞµÑ‚", "Ñ€ĞµĞºĞ²Ğ¸Ğ·Ğ¸Ñ‚Ñ‹", "ĞºĞ°Ñ€Ñ‚Ğ°", "Ğ»Ğ¸Ğ½Ğ¸Ñ", "Ğ·Ğ°Ñ‘Ğ¼"
            ],
            "urgency": ["ÑÑ€Ğ¾Ñ‡Ğ½Ğ¾", "Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾", "Ğ½ĞµĞ¼ĞµĞ´Ğ»ĞµĞ½Ğ½Ğ¾", "Ğ¿Ñ€ÑĞ¼Ğ¾ ÑĞµĞ¹Ñ‡Ğ°Ñ", "ÑÑ€Ğ¾Ğº"],
            "red_flags": [
                "Ğ½ÑƒĞ¶Ğ½Ñ‹ Ğ²Ğ°ÑˆĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ", "Ğ´Ğ°Ğ¹Ñ‚Ğµ ĞºĞ¾Ğ´Ñ‹", "Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ÑŒÑ‚Ğµ ÑĞ¼Ñ",
                "Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ´Ğ¸Ñ‚Ğµ Ğ»Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ", "Ğ²Ğ²ĞµÑÑ‚Ğ¸ Ğ¿Ğ¸Ğ½", "ÑĞºĞ¾Ğ¿Ğ¸Ñ€ÑƒĞ¹ ĞºĞ¾Ğ´"
            ]
        },
        "sim_swap": {
            "keywords": [
                "Ğ½Ğ¾Ğ¼ĞµÑ€", "ÑĞ¸Ğ¼ĞºĞ°", "Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€", "Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ",
                "Ğ¿ĞµÑ€ĞµÑ…Ğ¾Ğ´", "Ğ¼ĞµĞ³Ğ°Ñ„Ğ¾Ğ½", "Ğ¼Ñ‚Ñ", "Ğ±Ğ¸Ğ»Ğ°Ğ¹Ğ½", "Ñ‚ĞµĞ»Ğµ2"
            ],
            "urgency": ["Ğ·Ğ°Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½", "Ğ·Ğ°ĞºÑ€Ñ‹Ğ»Ğ¸", "Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°", "Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ"],
            "red_flags": [
                "Ğ¿ĞµÑ€ĞµĞ²ĞµÑÑ‚Ğ¸ Ğ½Ğ¾Ğ¼ĞµÑ€", "Ğ½Ğ¾Ğ²Ğ°Ñ ÑĞ¸Ğ¼ĞºĞ°", "Ğ¿ĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸ Ğ½Ğ° Ğ½Ğ°Ñ",
                "Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸ Ñ‚ĞµĞ»ĞµÑ„Ğ¾Ğ½", "Ñ‚Ğ°Ñ€Ğ¸Ñ„ Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ñ‚ÑÑ"
            ]
        },
        "investment": {
            "keywords": [
                "Ğ¸Ğ½Ğ²ĞµÑÑ‚Ğ¸Ñ†Ğ¸Ğ¸", "Ğ¿Ñ€Ğ¸Ğ±Ñ‹Ğ»ÑŒ", "Ğ´Ğ¾Ñ…Ğ¾Ğ´", "Ğ°ĞºÑ†Ğ¸Ğ¸", "ĞºÑ€Ğ¸Ğ¿Ñ‚Ğ¾",
                "Ğ±Ğ¸Ñ‚Ğ¾Ğº", "ethereum", "Ñ‚Ñ€ĞµĞ¹Ğ´Ğ¸Ğ½Ğ³", "Ñ„Ğ¾Ñ€ĞµĞºÑ"
            ],
            "urgency": ["Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ÑĞµĞ³Ğ¾Ğ´Ğ½Ñ", "Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ÑÑ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ", "Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¾", "Ğ·Ğ°Ğ²Ñ‚Ñ€Ğ° Ğ¿Ğ¾Ğ´Ğ¾Ñ€Ğ¾Ğ¶Ğ°ĞµÑ‚"],
            "red_flags": [
                "Ğ³Ğ°Ñ€Ğ°Ğ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ´Ğ¾Ñ…Ğ¾Ğ´", "100% Ğ¿Ñ€Ğ¸Ğ±Ñ‹Ğ»ÑŒ", "Ğ¾Ñ‚ĞºÑƒĞ¿Ğ¾Ğº Ğ³Ğ°Ñ€Ğ°Ğ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½",
                "Ğ²Ğ½ĞµÑĞ¸Ñ‚Ğµ Ğ´ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚", "Ğ¸Ğ½Ğ²ĞµÑÑ‚Ğ¸Ñ€ÑƒĞ¹ ÑĞµĞ¹Ñ‡Ğ°Ñ"
            ]
        },
        "utility": {
            "keywords": [
                "ĞºĞ²Ğ°Ñ€Ñ‚Ğ¸Ñ€Ğ°", "ĞºĞ¾Ğ¼Ğ¼ÑƒĞ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ", "ÑĞ»ĞµĞºÑ‚Ñ€Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾", "Ğ²Ğ¾Ğ´Ğ°",
                "Ğ³Ğ°Ğ·", "Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚", "ÑÑ‡ĞµÑ‚", "Ğ¾Ğ¿Ğ»Ğ°Ñ‚Ğ°", "Ğ–ĞšĞ¥"
            ],
            "urgency": ["Ğ¿ĞµÑ€ĞµĞºÑ€Ğ¾ÑÑ‚", "Ğ¾Ñ‚ĞºĞ»ÑÑ‡Ğ°Ñ‚", "ÑÑ€Ğ¾Ğº", "Ğ·Ğ°Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ", "Ğ½ĞµĞ¼ĞµĞ´Ğ»ĞµĞ½Ğ½Ğ¾"],
            "red_flags": [
                "Ğ¿Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚Ğµ ÑÑ‡ĞµÑ‚", "Ğ¿ĞµÑ€ĞµĞ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ´ĞµĞ½ÑŒĞ³Ğ¸", "ÑÑ€Ğ¾Ğº Ğ¸ÑÑ‚ĞµĞºĞ°ĞµÑ‚",
                "Ğ´ĞµĞ½ÑŒĞ³Ğ¸ Ğ½ÑƒĞ¶Ğ½Ñ‹ ÑĞµĞ³Ğ¾Ğ´Ğ½Ñ", "Ğ¸Ğ½Ğ°Ñ‡Ğµ Ğ¾Ñ‚ĞºĞ»ÑÑ‡Ğ¸Ğ¼"
            ]
        },
        "lottery": {
            "keywords": [
                "Ğ²Ñ‹Ğ¸Ğ³Ñ€Ğ°Ğ»", "Ğ¿Ñ€Ğ¸Ğ·", "Ğ»Ğ¾Ñ‚ĞµÑ€ĞµÑ", "Ğ¿Ğ¾Ğ´Ğ°Ñ€Ğ¾Ğº", "Ğ²ĞµĞ·Ñ‘Ñ‚",
                "ÑƒĞ´Ğ°Ñ‡Ğ°", "Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ¾Ğ½", "Ğ½Ğ°Ğ³Ñ€Ğ°Ğ´Ğ°", "Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ"
            ],
            "urgency": ["ÑĞ¿ĞµÑˆĞ¸", "ÑĞºĞ¾Ñ€Ğ¾ Ğ¸ÑÑ‚ĞµÑ‡ĞµÑ‚", "ÑÑ€Ğ¾Ğº Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½"],
            "red_flags": [
                "Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ÑŒ ĞºĞ¾Ğ¼Ğ¸ÑÑĞ¸Ñ", "Ğ²Ğ½ĞµÑĞ¸ Ğ´ĞµĞ½ÑŒĞ³Ğ¸", "Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ´Ğ¸ ÑƒÑ‡Ğ°ÑÑ‚Ğ¸Ğµ",
                "Ğ¿ĞµÑ€ĞµĞ²ĞµĞ´Ğ¸", "Ğ°ĞºÑ‚Ğ¸Ğ²Ğ¸Ñ€ÑƒĞ¹ Ğ¿Ñ€Ğ¸Ğ·"
            ]
        }
    }
    
    @staticmethod
    def analyze_text(text: str) -> dict:
        """Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ° (Ğ±ĞµĞ· LLM)"""
        
        text_lower = text.lower()
        scores = {}
        
        for fraud_type, patterns in FraudAnalyzer.FRAUD_PATTERNS.items():
            score = 0
            matched_flags = []
            
            # Keywords: 1 Ğ±Ğ°Ğ»Ğ»
            for keyword in patterns["keywords"]:
                if keyword in text_lower:
                    score += 1
            
            # Urgency: 2 Ğ±Ğ°Ğ»Ğ»Ğ°
            for urgency in patterns["urgency"]:
                if urgency in text_lower:
                    score += 2
            
            # Red flags: 3 Ğ±Ğ°Ğ»Ğ»Ğ°
            for flag in patterns["red_flags"]:
                if flag in text_lower:
                    score += 3
                    matched_flags.append(flag)
            
            scores[fraud_type] = {
                "score": score,
                "flags": matched_flags
            }
        
        # ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ğ»ÑƒÑ‡ÑˆĞ¸Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
        best_type = max(scores, key=lambda x: scores[x]["score"])
        best_score = scores[best_type]["score"]
        
        # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ñ€Ğ¸ÑĞº
        if best_score >= 40:
            risk_level = "high"
            confidence = min(0.95, best_score / 100)
        elif best_score >= 20:
            risk_level = "medium"
            confidence = min(0.80, best_score / 50)
        elif best_score >= 5:
            risk_level = "low"
            confidence = best_score / 20
        else:
            risk_level = "none"
            confidence = 0.0
        
        return {
            "fraud_type": best_type if best_score > 0 else "unknown",
            "risk_level": risk_level,
            "confidence": confidence,
            "red_flags": scores[best_type]["flags"][:5],
            "local_score": best_score,
            "method": "local_patterns"
        }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LLM ĞŸĞ ĞĞ’ĞĞ™Ğ”Ğ•Ğ  (Deepseek + ChatGPT)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class LLMProvider:
    """ĞŸÑ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€ LLM Ñ fallback Ğ»Ğ¾Ğ³Ğ¸ĞºĞ¾Ğ¹"""
    
    def __init__(self, deepseek_key: str = None, chatgpt_key: str = None):
        self.deepseek_key = deepseek_key
        self.chatgpt_key = chatgpt_key
    
    async def analyze(self, text: str) -> Optional[dict]:
        """ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ñ fallback ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸ĞµĞ¹"""
        
        # Ğ¨ĞĞ“ 1: ĞŸÑ‹Ñ‚Ğ°ĞµĞ¼ÑÑ Deepseek (Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾, Ğ´ĞµÑˆĞµĞ²Ğ¾)
        if self.deepseek_key:
            logger.info("ğŸ”„ Trying Deepseek...")
            result = await self._analyze_deepseek(text)
            if result:
                logger.info("âœ… Deepseek ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ²ĞµÑ€Ğ½ÑƒĞ» Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚")
                result["provider"] = "deepseek"
                return result
            logger.warning("âš ï¸ Deepseek failed, trying ChatGPT...")
        
        # Ğ¨ĞĞ“ 2: Fallback Ğ½Ğ° ChatGPT
        if self.chatgpt_key:
            logger.info("ğŸ”„ Trying ChatGPT...")
            result = await self._analyze_chatgpt(text)
            if result:
                logger.info("âœ… ChatGPT ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ²ĞµÑ€Ğ½ÑƒĞ» Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚")
                result["provider"] = "chatgpt"
                return result
            logger.warning("âš ï¸ ChatGPT failed")
        
        logger.error("âŒ All LLM providers failed")
        return None
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # DEEPSEEK
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    async def _analyze_deepseek(self, text: str) -> Optional[dict]:
        """Deepseek API"""
        
        prompt = f"""Ğ¢Ñ‹ ÑĞºÑĞ¿ĞµÑ€Ñ‚ Ğ² Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğµ Ğ¼Ğ¾ÑˆĞµĞ½Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ·Ğ²Ğ¾Ğ½ĞºĞ¾Ğ² Ğ² Ğ Ğ¾ÑÑĞ¸Ğ¸.

ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ Ñ‚ĞµĞºÑÑ‚ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ° Ğ¸ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸:
1. Ğ¢Ğ¸Ğ¿ Ğ¼Ğ¾ÑˆĞµĞ½Ğ½Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ° (credit/sim_swap/investment/utility/lottery/legitimate/unknown)
2. Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ (low/medium/high)
3. ĞŸÑ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ ÑĞºĞ°Ğ¼Ğ° (ÑĞ¿Ğ¸ÑĞ¾Ğº, 3-5 ÑˆÑ‚ÑƒĞº)
4. Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ñ (Ñ‡Ñ‚Ğ¾ Ğ´ĞµĞ»Ğ°Ñ‚ÑŒ)

ĞÑ‚Ğ²ĞµÑ‚ÑŒ Ğ¢ĞĞ›Ğ¬ĞšĞ JSON (Ğ±ĞµĞ· Ğ¼Ğ°Ñ€ĞºĞ´Ğ°ÑƒĞ½Ğ°, Ğ±ĞµĞ· ```
{{
  "fraud_type": "...",
  "risk_level": "low|medium|high",
  "red_flags": ["Ñ„Ğ»Ğ°Ğ³1", "Ñ„Ğ»Ğ°Ğ³2"],
  "recommendation": "Ñ‚ĞµĞºÑÑ‚ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸",
  "confidence": 0.85
}}

Ğ¢Ğ•ĞšĞ¡Ğ¢:
{text}"""
        
        try:
            async with aiohttp.ClientSession() as session:
                headers = {
                    "Authorization": f"Bearer {self.deepseek_key}",
                    "Content-Type": "application/json",
                }
                
                payload = {
                    "model": "deepseek-chat",
                    "messages": [
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": 0.3,
                    "max_tokens": 800
                }
                
                logger.debug(f"ğŸ“¤ Sending request to Deepseek")
                
                async with session.post(
                    "https://api.deepseek.com/chat/completions",
                    json=payload,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=ANALYSIS_TIMEOUT)
                ) as resp:
                    logger.info(f"ğŸ“¥ Deepseek response status: {resp.status}")
                    
                    if resp.status != 200:
                        error_text = await resp.text()
                        logger.error(f"âŒ Deepseek HTTP error {resp.status}: {error_text[:200]}")
                        return None
                    
                    result = await resp.json()
                    logger.debug(f"ğŸ“¦ Deepseek raw response: {str(result)[:500]}")
                    
                    try:
                        # âœ… Ğ˜Ğ¡ĞŸĞ ĞĞ’ĞšĞ: ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³
                        if "choices" not in result:
                            logger.error(f"âŒ No 'choices' in response: {result}")
                            return None
                        
                        if not isinstance(result["choices"], list) or len(result["choices"]) == 0:
                            logger.error(f"âŒ 'choices' is not a list or empty: {result['choices']}")
                            return None
                        
                        choice = result["choices"]
                        
                        if "message" not in choice:
                            logger.error(f"âŒ No 'message' in choice: {choice}")
                            return None
                        
                        if "content" not in choice["message"]:
                            logger.error(f"âŒ No 'content' in message: {choice['message']}")
                            return None
                        
                        response_text = choice["message"]["content"]
                        logger.debug(f"ğŸ“ Deepseek message: {response_text[:300]}")
                        
                        # ĞŸĞ°Ñ€ÑĞ¸Ğ¼ JSON
                        gpt_result = json.loads(response_text)
                        logger.info(f"âœ… Successfully parsed Deepseek JSON: {gpt_result.get('fraud_type')}")
                        return gpt_result
                        
                    except json.JSONDecodeError as e:
                        logger.error(f"âŒ Deepseek JSON decode error: {e}")
                        logger.error(f"   Response text: {response_text[:300] if 'response_text' in locals() else 'N/A'}")
                        return None
                    except (KeyError, IndexError, TypeError) as e:
                        logger.error(f"âŒ Deepseek structure error: {type(e).__name__}: {e}")
                        logger.error(f"   Full response: {result}")
                        return None
        
        except asyncio.TimeoutError:
            logger.error("âŒ Deepseek timeout (15s)")
            return None
        except Exception as e:
            logger.error(f"âŒ Deepseek exception: {type(e).__name__}: {e}", exc_info=True)
            return None
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # CHATGPT (OpenAI)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    async def _analyze_chatgpt(self, text: str) -> Optional[dict]:
        """ChatGPT API (OpenAI)"""
        
        prompt = f"""Analyze this phone call text for scam/fraud in Russian context.

Determine:
1. Fraud type (credit/sim_swap/investment/utility/lottery/legitimate/unknown)
2. Risk level (low/medium/high)
3. Scam indicators (3-5 items)
4. Recommendation for user

Answer ONLY as JSON (no markdown):
{{
  "fraud_type": "...",
  "risk_level": "low|medium|high",
  "red_flags": ["flag1", "flag2"],
  "recommendation": "advice",
  "confidence": 0.85
}}

TEXT:
{text}"""
        
        try:
            async with aiohttp.ClientSession() as session:
                headers = {
                    "Authorization": f"Bearer {self.chatgpt_key}",
                    "Content-Type": "application/json",
                }
                
                payload = {
                    "model": "gpt-4-mini",
                    "messages": [
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": 0.3,
                    "max_tokens": 800
                }
                
                logger.debug(f"ğŸ“¤ Sending request to ChatGPT")
                
                async with session.post(
                    "https://api.openai.com/v1/chat/completions",
                    json=payload,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=ANALYSIS_TIMEOUT)
                ) as resp:
                    logger.info(f"ğŸ“¥ ChatGPT response status: {resp.status}")
                    
                    if resp.status != 200:
                        error_text = await resp.text()
                        logger.error(f"âŒ ChatGPT HTTP error {resp.status}: {error_text[:200]}")
                        return None
                    
                    result = await resp.json()
                    logger.debug(f"ğŸ“¦ ChatGPT raw response: {str(result)[:500]}")
                    
                    try:
                        # âœ… Ğ˜Ğ¡ĞŸĞ ĞĞ’ĞšĞ: ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³
                        if "choices" not in result:
                            logger.error(f"âŒ No 'choices' in response: {result}")
                            return None
                        
                        if not isinstance(result["choices"], list) or len(result["choices"]) == 0:
                            logger.error(f"âŒ 'choices' is not a list or empty: {result['choices']}")
                            return None
                        
                        choice = result["choices"]
                        
                        if "message" not in choice:
                            logger.error(f"âŒ No 'message' in choice: {choice}")
                            return None
                        
                        if "content" not in choice["message"]:
                            logger.error(f"âŒ No 'content' in message: {choice['message']}")
                            return None
                        
                        response_text = choice["message"]["content"]
                        logger.debug(f"ğŸ“ ChatGPT message: {response_text[:300]}")
                        
                        # ĞŸĞ°Ñ€ÑĞ¸Ğ¼ JSON
                        gpt_result = json.loads(response_text)
                        logger.info(f"âœ… Successfully parsed ChatGPT JSON: {gpt_result.get('fraud_type')}")
                        return gpt_result
                        
                    except json.JSONDecodeError as e:
                        logger.error(f"âŒ ChatGPT JSON decode error: {e}")
                        logger.error(f"   Response text: {response_text[:300] if 'response_text' in locals() else 'N/A'}")
                        return None
                    except (KeyError, IndexError, TypeError) as e:
                        logger.error(f"âŒ ChatGPT structure error: {type(e).__name__}: {e}")
                        logger.error(f"   Full response: {result}")
                        return None
        
        except asyncio.TimeoutError:
            logger.error("âŒ ChatGPT timeout (15s)")
            return None
        except Exception as e:
            logger.error(f"âŒ ChatGPT exception: {type(e).__name__}: {e}", exc_info=True)
            return None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ“Ğ›ĞĞ‘ĞĞ›Ğ¬ĞĞ«Ğ™ LLM ĞŸĞ ĞĞ’ĞĞ™Ğ”Ğ•Ğ 
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

llm_provider: Optional[LLMProvider] = None

async def initialize_llm():
    """Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ LLM Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ¿ÑƒÑĞºĞµ Ğ±Ğ¾Ñ‚Ğ°"""
    global llm_provider
    
    llm_provider = LLMProvider(
        deepseek_key=DEEPSEEK_API_KEY,
        chatgpt_key=CHATGPT_API_KEY
    )
    
    available_providers = []
    if DEEPSEEK_API_KEY:
        available_providers.append("Deepseek")
    if CHATGPT_API_KEY:
        available_providers.append("ChatGPT")
    
    if available_providers:
        print(f"âœ… LLM Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ñ‹: {', '.join(available_providers)}")
    else:
        print("âš ï¸  LLM Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ñ‹ Ğ½Ğµ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹, Ğ±ÑƒĞ´ĞµÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TELEGRAM ĞĞ‘Ğ ĞĞ‘ĞĞ¢Ğ§Ğ˜ĞšĞ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° /start"""
    
    welcome_text = """
ğŸ›¡ï¸ <b>Ğ”Ğ¾Ğ±Ñ€Ğ¾ Ğ¿Ğ¾Ğ¶Ğ°Ğ»Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ² Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ¼Ğ¾ÑˆĞµĞ½Ğ½Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ°!</b>

Ğ¯ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑ Ñ‚ĞµĞºÑÑ‚ Ğ·Ğ²Ğ¾Ğ½ĞºĞ¾Ğ² Ğ¸ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑÑ, ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ»Ğ¸ ÑÑ‚Ğ¾ Ğ¼Ğ¾ÑˆĞµĞ½Ğ½Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾Ğ¼.

<b>ğŸ“ ĞšĞ°Ğº Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ:</b>
1ï¸âƒ£ ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ğ» Ğ¼Ğ¾ÑˆĞµĞ½Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ·Ğ²Ğ¾Ğ½Ğ¾Ğº?
2ï¸âƒ£ ĞÑ‚ĞºÑ€Ğ¾Ğ¹ Ğ´Ğ¸ĞºÑ‚Ğ¾Ñ„Ğ¾Ğ½ (Ğ¸Ğ»Ğ¸ Ğ²Ñ‹Ğ¿Ğ¸ÑˆĞ¸ Ñ‚ĞµĞºÑÑ‚)
3ï¸âƒ£ ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ÑŒ Ğ¼Ğ½Ğµ Ñ‚ĞµĞºÑÑ‚ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ°
4ï¸âƒ£ Ğ—Ğ° 1-2 ÑĞµĞº Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸ÑˆÑŒ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·

<b>â±ï¸ ĞŸÑ€Ğ¸Ğ¼ĞµÑ€:</b>
de>ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, ÑÑ‚Ğ¾ ÑĞ»ÑƒĞ¶Ğ±Ğ° Ğ±Ğ°Ğ½ĞºĞ°. Ğ£ Ğ²Ğ°Ñ Ğ¾Ğ´Ğ¾Ğ±Ñ€ĞµĞ½Ğ° ĞºÑ€ĞµĞ´Ğ¸Ñ‚Ğ½Ğ°Ñ Ğ»Ğ¸Ğ½Ğ¸Ñ Ğ½Ğ° 500000 Ñ€ÑƒĞ±Ğ»ĞµĞ¹. Ğ¡Ñ€Ğ¾Ñ‡Ğ½Ğ¾ Ğ½ÑƒĞ¶Ğ½Ñ‹ ĞºĞ¾Ğ´Ñ‹ Ñ Ğ²Ğ°ÑˆĞµĞ¹ ĞºĞ°Ñ€Ñ‚Ñ‹ Ğ´Ğ»Ñ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ğ¸.</code>

/help - ÑĞ¿Ñ€Ğ°Ğ²ĞºĞ°
/example - Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°
/stats - ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°
    """
    
    await update.message.reply_text(welcome_text, parse_mode="HTML")

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° /help"""
    
    help_text = """
<b>ğŸ“– Ğ¡Ğ¿Ñ€Ğ°Ğ²ĞºĞ°</b>

<b>Ğ§Ñ‚Ğ¾ Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑ:</b>
âœ… ĞšÑ€ĞµĞ´Ğ¸Ñ‚Ğ½Ñ‹Ğµ Ğ¼Ğ¾ÑˆĞµĞ½Ğ½Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ°
âœ… SIM-swap (Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´ Ğ½Ğ¾Ğ¼ĞµÑ€Ğ°)
âœ… Ğ˜Ğ½Ğ²ĞµÑÑ‚Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ°Ñ„Ñ‘Ñ€Ñ‹
âœ… ĞšĞ¾Ğ¼Ğ¼ÑƒĞ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ğ»Ğ°Ñ‚ĞµĞ¶Ğ¸ (Ğ¿Ğ¾Ğ´Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğµ)
âœ… Ğ›Ğ¾Ñ‚ĞµÑ€ĞµĞ¸ Ğ¸ Ñ€Ğ¾Ğ·Ñ‹Ğ³Ñ€Ñ‹ÑˆĞ¸
âœ… Ğ›ĞµĞ³Ğ¸Ñ‚Ğ¸Ğ¼Ğ½Ñ‹Ğµ Ğ·Ğ²Ğ¾Ğ½ĞºĞ¸

<b>ĞšĞ°Ğº ÑÑ‚Ğ¾ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚:</b>
1. Ğ¢Ñ‹ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑˆÑŒ Ñ‚ĞµĞºÑÑ‚ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ°
2. Ğ¯ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾ (Ğ¿Ñ€Ğ¸Ğ²Ğ°Ñ‚Ğ½Ğ¾)
3. ĞŸĞ¾Ñ‚Ğ¾Ğ¼ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ Ğ½Ğ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºÑƒ AI (Deepseek/ChatGPT)
4. Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ñ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒÑ

<b>ĞŸÑ€Ğ¸Ğ²Ğ°Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ:</b>
ğŸ” Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ ĞĞ• ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑÑ‚ÑÑ
ğŸ” ĞĞ• Ğ¿ĞµÑ€ĞµĞ´Ğ°ÑÑ‚ÑÑ Ñ‚Ñ€ĞµÑ‚ÑŒĞ¸Ğ¼ Ğ»Ğ¸Ñ†Ğ°Ğ¼
ğŸ” Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑÑ‚ÑÑ

/start - Ğ½Ğ°Ñ‡Ğ°Ñ‚ÑŒ
/example - Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€
/stats - ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°
    """
    
    await update.message.reply_text(help_text, parse_mode="HTML")

async def example_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°"""
    
    example_text = """
<b>ĞŸĞ Ğ˜ĞœĞ•Ğ  ĞœĞĞ¨Ğ•ĞĞĞ˜Ğ§Ğ•Ğ¡ĞšĞĞ“Ğ Ğ—Ğ’ĞĞĞšĞ:</b>

"ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, ÑÑ‚Ğ¾ ÑĞ»ÑƒĞ¶Ğ±Ğ° Ğ±Ğ°Ğ½ĞºĞ°. Ğ£ Ğ²Ğ°Ñ Ğ¾Ğ´Ğ¾Ğ±Ñ€ĞµĞ½Ğ° ĞºÑ€ĞµĞ´Ğ¸Ñ‚Ğ½Ğ°Ñ Ğ»Ğ¸Ğ½Ğ¸Ñ Ğ½Ğ° 500000 Ñ€ÑƒĞ±Ğ»ĞµĞ¹. Ğ¡Ñ€Ğ¾Ñ‡Ğ½Ğ¾ Ğ½ÑƒĞ¶Ğ½Ñ‹ ĞºĞ¾Ğ´Ñ‹ Ñ Ğ²Ğ°ÑˆĞµĞ¹ ĞºĞ°Ñ€Ñ‚Ñ‹ Ğ´Ğ»Ñ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ğ¸."

ğŸ”´ <b>Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢ ĞĞĞĞ›Ğ˜Ğ—Ğ:</b>

<b>ğŸ¯ Ğ¢Ğ¸Ğ¿:</b> credit
<b>âš ï¸ ĞĞ¿Ğ°ÑĞ½Ğ¾ÑÑ‚ÑŒ:</b> HIGH
<b>ğŸ“Š Ğ£Ğ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ:</b> 95%

<b>ğŸš© ĞŸÑ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ ÑĞºĞ°Ğ¼Ğ°:</b>
-  Ğ½ÑƒĞ¶Ğ½Ñ‹ Ğ²Ğ°ÑˆĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
-  Ğ´Ğ°Ğ¹Ñ‚Ğµ ĞºĞ¾Ğ´Ñ‹ Ñ ĞºĞ°Ñ€Ñ‚Ñ‹
-  ÑÑ€Ğ¾Ñ‡Ğ½Ğ¾

<b>ğŸ’¡ Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ñ:</b>
ĞĞ˜ĞšĞĞ“Ğ”Ğ Ğ½Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰Ğ°Ğ¹Ñ‚Ğµ ĞºĞ¾Ğ´Ñ‹ Ñ ĞºĞ°Ñ€Ñ‚Ñ‹! Ğ­Ñ‚Ğ¾ 100% Ğ¼Ğ¾ÑˆĞµĞ½Ğ½Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾. ĞŸĞ¾Ğ²ĞµÑÑŒÑ‚Ğµ Ñ‚Ñ€ÑƒĞ±ĞºÑƒ Ğ¸ Ğ·Ğ°Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€ÑƒĞ¹Ñ‚Ğµ Ğ½Ğ¾Ğ¼ĞµÑ€.
    """
    
    await update.message.reply_text(example_text, parse_mode="HTML")

async def analyze_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ°"""
    
    text = update.message.text
    user_id = update.effective_user.id
    
    logger.info(f"ğŸ“¨ New message from user {user_id}: {text[:50]}...")
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ´Ğ»Ğ¸Ğ½Ñƒ
    if len(text) < MIN_TEXT_LENGTH:
        await update.message.reply_text(
            f"âŒ Ğ¢ĞµĞºÑÑ‚ ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹.\n"
            f"ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ÑŒ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ° (Ğ¼Ğ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ {MIN_TEXT_LENGTH} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²)."
        )
        return
    
    # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ ÑÑ‚Ğ°Ñ‚ÑƒÑ
    status_msg = await update.message.reply_text("â³ ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€...\n\nâš¡ Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·...")
    
    try:
        # Ğ¨ĞĞ“ 1: Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· (Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾, ~100ms)
        logger.info("ğŸ”„ Starting local analysis...")
        local_result = FraudAnalyzer.analyze_text(text)
        logger.info(f"âœ… Local analysis done: {local_result.get('fraud_type')} ({local_result.get('risk_level')})")
        
        # Ğ¨ĞĞ“ 2: GPT Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· (Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹)
        await status_msg.edit_text(
            "â³ ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€...\n\n"
            "âš¡ Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·: âœ…\n"
            "ğŸ§  AI Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· (Deepseek/ChatGPT)..."
        )
        
        gpt_result = None
        if llm_provider:
            logger.info("ğŸ”„ Requesting LLM analysis...")
            gpt_result = await llm_provider.analyze(text)
            if gpt_result:
                logger.info(f"âœ… LLM analysis done: {gpt_result.get('provider')}")
            else:
                logger.warning("âš ï¸ LLM analysis returned None")
        
        # Ğ¨ĞĞ“ 3: ĞšĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ¸Ñ€ÑƒĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
        if gpt_result:
            final_result = gpt_result
            logger.info(f"ğŸ“Š Using LLM result: {gpt_result.get('provider')}")
        else:
            final_result = local_result
            logger.info("ğŸ“Š Using local result (LLM failed)")
        
        # Ğ¨ĞĞ“ 4: Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¾Ñ‚Ğ²ĞµÑ‚
        risk_emoji = {
            "low": "ğŸŸ¢",
            "medium": "ğŸŸ¡",
            "high": "ğŸ”´"
        }.get(final_result.get("risk_level"), "â“")
        
        confidence_percent = int(final_result.get("confidence", 0) * 100)
        fraud_type = final_result.get("fraud_type", "unknown")
        risk_level = final_result.get("risk_level", "unknown").upper()
        
        red_flags = final_result.get("red_flags", [])
        recommendation = final_result.get("recommendation", "ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ·Ğ²Ğ¾Ğ½ĞºĞ°")
        provider = final_result.get("provider", "local")
        
        response = f"""
{risk_emoji} <b>Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢ ĞĞĞĞ›Ğ˜Ğ—Ğ</b>

<b>ğŸ¯ Ğ¢Ğ¸Ğ¿ Ğ¼Ğ¾ÑˆĞµĞ½Ğ½Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ°:</b> {fraud_type}
<b>âš ï¸ Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸:</b> {risk_level}
<b>ğŸ“Š Ğ£Ğ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ:</b> {confidence_percent}%

<b>ğŸš© ĞŸÑ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ ÑĞºĞ°Ğ¼Ğ°:</b>
{chr(10).join(f"-  {flag}" for flag in red_flags) if red_flags else "-  ĞĞµ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ñ‹"}

<b>ğŸ’¡ Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ñ:</b>
{recommendation}

<b>ğŸ“ ĞĞ½Ğ°Ğ»Ğ¸Ğ·:</b> {provider}
        """
        
        await status_msg.edit_text(response, parse_mode="HTML")
        logger.info(f"âœ… Response sent to user {user_id}")
        
    except Exception as e:
        logger.error(f"âŒ Analysis error: {type(e).__name__}: {e}", exc_info=True)
        await status_msg.edit_text(
            f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğµ:\n{str(e)[:100]}\n\n"
            "ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹ ĞµÑ‰Ñ‘ Ñ€Ğ°Ğ·."
        )

async def stats_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°"""
    
    stats_text = """
ğŸ“Š <b>Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° (Ğ±ĞµÑ‚Ğ°)</b>

Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ±ÑƒĞ´ĞµÑ‚ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ğ² ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹ Ğ²ĞµÑ€ÑĞ¸Ğ¸.
ĞŸĞ¾ĞºĞ° Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ñ‹! ğŸ›¡ï¸
    """
    
    await update.message.reply_text(stats_text, parse_mode="HTML")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ—ĞĞŸĞ£Ğ¡Ğš Ğ‘ĞĞ¢Ğ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ±Ğ¾Ñ‚Ğ°"""
    
    logger.info("=" * 50)
    logger.info("ğŸ¤– Starting GuardCall Bot...")
    logger.info("=" * 50)
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ
    app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    
    # Post-init callback
    async def post_init(context):
        logger.info("ğŸ”„ Initializing bot...")
        await initialize_llm()
        logger.info("âœ… Bot initialization complete!")
    
    app.post_init = post_init
    
    # Ğ ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ¸ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´
    app.add_handler(CommandHandler("start", start_command))
    app.add_handler(CommandHandler("help", help_command))
    app.add_handler(CommandHandler("example", example_command))
    app.add_handler(CommandHandler("stats", stats_command))
    
    # Ğ ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ñ… ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, analyze_message))
    
    # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼
    logger.info("ğŸ¤– Bot is running!")
    logger.info(f"ğŸ“± Open: https://t.me/guardcallbot")
    logger.info("=" * 50)
    
    app.run_polling()

if __name__ == "__main__":
    main()
